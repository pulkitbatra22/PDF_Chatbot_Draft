{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4b507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain==0.0.184\n",
    "!pip install PyPDF2==3.0.1\n",
    "!pip install python-dotenv==1.0.0\n",
    "!pip install streamlit==1.18.1\n",
    "!pip install openai==0.27.6\n",
    "!pip install faiss-cpu==1.7.4\n",
    "!pip install altair==4\n",
    "!pip install tiktoken==0.4.0\n",
    "# uncomment to use huggingface llms\n",
    "!pip install huggingface-hub==0.14.1\n",
    "\n",
    "# uncomment to use instructor embeddings\n",
    "!pip install InstructorEmbedding==1.0.1\n",
    "!pip install sentence-transformers==2.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9458a3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc99cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile yt_app1.py\n",
    "\n",
    "\n",
    "import streamlit as st\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from htmlTemplates import css, bot_template, user_template\n",
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "def get_pdf_text(pdf_docs):\n",
    "    text = \"\"\n",
    "    for pdf in pdf_docs:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        length_function=len\n",
    "    )\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    return chunks\n",
    "\n",
    "API_KEY= \"XXX\"\n",
    "\n",
    "def get_vectorstore(text_chunks):\n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=API_KEY)\n",
    "    #embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\")\n",
    "    vectorstore = FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "def get_conversation_chain(vectorstore):\n",
    "    llm = ChatOpenAI(openai_api_key=API_KEY)\n",
    "    # llm = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\":0.5, \"max_length\":512})\n",
    "\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key='chat_history', return_messages=True)\n",
    "    conversation_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(),\n",
    "        memory=memory\n",
    "    )\n",
    "    return conversation_chain\n",
    "\n",
    "def handle_userinput(user_question):\n",
    "    response = st.session_state.conversation({'question': user_question})\n",
    "    st.session_state.chat_history = response['chat_history']\n",
    "\n",
    "    for i, message in enumerate(st.session_state.chat_history):\n",
    "        if i % 2 == 0:\n",
    "            st.write(user_template.replace(\n",
    "                \"{{MSG}}\", message.content), unsafe_allow_html=True)\n",
    "        else:\n",
    "            st.write(bot_template.replace(\n",
    "                \"{{MSG}}\", message.content), unsafe_allow_html=True)\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"PDFs Chatbot\")\n",
    "    st.write(css, unsafe_allow_html=True)\n",
    "\n",
    "    if \"conversation\" not in st.session_state:\n",
    "        st.session_state.conversation = None\n",
    "    if \"chat_history\" not in st.session_state:\n",
    "        st.session_state.chat_history = None\n",
    "\n",
    "    st.header(\"Chatbot for multiple PDFs\")\n",
    "    user_question = st.text_input(\"Ask a question about your PDFs:\")\n",
    "    if user_question:\n",
    "        handle_userinput(user_question)\n",
    "\n",
    "    with st.sidebar:\n",
    "        st.subheader(\"Your documents\")\n",
    "        pdf_docs = st.file_uploader( \"Upload your PDFs here and click on 'Process'\", accept_multiple_files=True)\n",
    "        if st.button(\"Process\"):\n",
    "            with st.spinner(\"Processing\"):\n",
    "                # get pdf text\n",
    "                raw_text = get_pdf_text(pdf_docs)\n",
    "                #st.write(raw_text)\n",
    "\n",
    "                # get the text chunks\n",
    "                text_chunks = get_text_chunks(raw_text)\n",
    "                \n",
    "\n",
    "                # create vector store\n",
    "                vectorstore = get_vectorstore(text_chunks)\n",
    "                \n",
    "\n",
    "                # create conversation chain\n",
    "                st.session_state.conversation = get_conversation_chain(vectorstore)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cb4f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run yt_app1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76dc3cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
